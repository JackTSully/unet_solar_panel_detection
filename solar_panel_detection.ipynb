{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "BuzqJHSyw0O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "\n",
        "def create_tiles(input_file, output_dir, tile_size_x, tile_size_y, overlap=0):\n",
        "    input_ds = gdal.Open(input_file)\n",
        "    cols = input_ds.RasterXSize\n",
        "    rows = input_ds.RasterYSize\n",
        "\n",
        "    for i in range(0, cols, tile_size_x - overlap):\n",
        "        for j in range(0, rows, tile_size_y - overlap):\n",
        "            output_file = os.path.join(output_dir, f\"tile_{i}_{j}.tif\") #here\n",
        "            gdal.Translate(output_file, input_ds, srcWin=[i, j, tile_size_x, tile_size_y])\n",
        "\n",
        "    input_ds = None\n",
        "\n",
        "def show_images(images, titles=None):\n",
        "    if not titles:\n",
        "        titles = [img.shape for img in images]\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=len(images), figsize=(10, 30))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i], cmap=\"summer\")\n",
        "        ax.set_title(titles[i])\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def show_1image(image, size = (10,10)):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=size)\n",
        "    axes.imshow(image, cmap=\"summer\")\n",
        "    axes.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def del_dir_contents(dir_path):\n",
        "  for file in os.listdir(dir_path):\n",
        "    file_path = os.path.join(dir_path, file)\n",
        "    os.remove(file_path)\n"
      ],
      "metadata": {
        "id": "2bFqDjsUjY6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directory Setup\n",
        "Set paths according to where the files are located"
      ],
      "metadata": {
        "id": "ykgRhf5YnhPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "dir_parent = '/content'\n",
        "dir_in = '/content/drive/MyDrive/SeniorProjectMockup/input'\n",
        "file_name = 'bkk1_02.tif'\n",
        "\n",
        "# Output\n",
        "dir_tiles = '/content/tiles'\n",
        "dir_masks = '/content/masks'\n",
        "\n",
        "# Image dimensions\n",
        "dim = 512\n",
        "\n",
        "file_path = os.path.join(dir_in,file_name)"
      ],
      "metadata": {
        "id": "i9O3pvyIw7oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete contents of the Tile folder to have a fresh start"
      ],
      "metadata": {
        "id": "6qyl1Qc5m9y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del_path = dir_tiles\n",
        "try:\n",
        "  del_dir_contents(del_path)\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "2Sv2VXstlE1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tile folder and tiles from the input image (file_path)"
      ],
      "metadata": {
        "id": "aAgfxVFYnHO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(dir_tiles)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "create_tiles(file_path, dir_tiles, dim, dim, overlap=0)"
      ],
      "metadata": {
        "id": "ko97ETMNw88h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete contents of the Mask folder to have a fresh start"
      ],
      "metadata": {
        "id": "4OdIT90Coo8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del_path = dir_masks\n",
        "try:\n",
        "  del_dir_contents(del_path)\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "0weuah45ocG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Mask folder"
      ],
      "metadata": {
        "id": "B1q16GePot26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(dir_masks)\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "41hWaZyvoUb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup"
      ],
      "metadata": {
        "id": "eOlB54hJnvm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q segmentation-models\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "import segmentation_models as sm"
      ],
      "metadata": {
        "id": "FiaysRDUTaAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = 'inceptionresnetv2'"
      ],
      "metadata": {
        "id": "LqnmSL0jTcgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone_preprocess = sm.get_preprocessing(backbone)\n",
        "preprocess_fn = lambda x, y: (backbone_preprocess(x), y)"
      ],
      "metadata": {
        "id": "KwCmlxtATd7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set model_path according to where the model is located"
      ],
      "metadata": {
        "id": "gkRBykv7n5vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/SeniorProjectMockup/models/model_unet-inceptionresnetv2_T455_PT.keras\"\n",
        "model = keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects={\n",
        "        \"dice_loss\": sm.losses.DiceLoss(),\n",
        "        \"iou_score\": sm.metrics.IOUScore()\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "bLPWU5nLThf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Showcase"
      ],
      "metadata": {
        "id": "NFz_DoS7qVQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_size = (512, 512)\n",
        "threshold = 0.9\n",
        "tiles_left = len(os.listdir(dir_tiles))\n",
        "\n",
        "for tile in os.listdir(dir_tiles):\n",
        "  img_path = os.path.join(dir_tiles, tile)\n",
        "\n",
        "  src_ds = gdal.Open(img_path)\n",
        "\n",
        "  image = plt.imread(img_path)\n",
        "  image = image[:,:,:3]\n",
        "  image = image.astype(int)\n",
        "  #image = tf.image.resize(image, new_size)\n",
        "  processed_test_img = backbone_preprocess(image)\n",
        "\n",
        "  mask_4d = model.predict(np.expand_dims(processed_test_img, axis=(0)))\n",
        "  pred_mask_prob = np.squeeze(mask_4d, axis=0)\n",
        "  pred_mask = np.where(pred_mask_prob > threshold, 1, 0)\n",
        "\n",
        "  tile = tile.split('.')\n",
        "  mask_path = os.path.join(dir_masks,tile[0]+'_mask.'+tile[1])\n",
        "  cv2.imwrite(mask_path, pred_mask)\n",
        "\n",
        "  target_ds = gdal.Open(mask_path, gdal.GA_Update)\n",
        "  target_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
        "  target_ds.SetProjection(src_ds.GetProjection())\n",
        "  src_ds = None\n",
        "  target_ds = None\n",
        "\n",
        "  show_images((image, pred_mask), [tile[0], \"Model Prediciton\"])\n",
        "  tiles_left -= 1\n",
        "  print(\"tiles left\",tiles_left,\"...\")\n"
      ],
      "metadata": {
        "id": "zIWQIfd1T5oF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge mask tiles into one"
      ],
      "metadata": {
        "id": "Xw_i_w-yjL0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_tiles(input_dir, output_file):\n",
        "    # Get list of tile files\n",
        "    tile_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.tif')]\n",
        "\n",
        "    # Build VRT from tile files\n",
        "    vrt_options = gdal.BuildVRTOptions(resampleAlg='nearest')\n",
        "    vrt = gdal.BuildVRT(os.path.join(output_file + '.vrt'), tile_files, options=vrt_options)\n",
        "\n",
        "    try:\n",
        "        # Translate VRT to final output file\n",
        "        gdal.Translate(output_file, vrt)\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(\"Error during translation:\", e)\n",
        "        print(\"Applying transparency to problematic sections.\")\n",
        "\n",
        "        # Get NoData value\n",
        "        no_data_value = vrt.GetRasterBand(1).GetNoDataValue()\n",
        "\n",
        "        # Set transparent pixels\n",
        "        gdal.Translate(output_file, vrt, format='GTiff', creationOptions=['ALPHA=YES'], noData=no_data_value)\n",
        "\n",
        "    finally:\n",
        "        # Close datasets\n",
        "        vrt = None\n",
        "\n"
      ],
      "metadata": {
        "id": "hhXpTnu_-4nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = dir_masks\n",
        "output_file = \"merged_output.tif\"\n",
        "merge_tiles(input_dir, output_file)"
      ],
      "metadata": {
        "id": "MgIOK5XX-6HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_mask = '/content/merged_output.tif'\n",
        "image = Image.open(merged_mask)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = image.convert('L')\n",
        "\n",
        "show_1image(gray_image)"
      ],
      "metadata": {
        "id": "TnRxMBacLi1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array(gray_image)\n",
        "print(np.unique(numpy_array))"
      ],
      "metadata": {
        "id": "3LRoZfT3tjRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract LatLongBound\n",
        "This step is used to extract the values used for overlaying the image on Google Map Javascript API"
      ],
      "metadata": {
        "id": "T4SfMiJojC0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal, osr\n",
        "from typing import Tuple\n",
        "\n",
        "def get_geotiff_bounds(file_path: str) -> Tuple[float, float, float, float]:\n",
        "    \"\"\"\n",
        "    Get the bounding box (in WGS84 coordinates) of a GeoTIFF file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the GeoTIFF file.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float, float]: Bounding box coordinates in the order (min_lng, min_lat, max_lng, max_lat).\n",
        "    \"\"\"\n",
        "    # Open the GeoTIFF file\n",
        "    dataset = gdal.Open(file_path)\n",
        "\n",
        "    # Reproject to WGS84\n",
        "    target_srs = osr.SpatialReference()\n",
        "    target_srs.ImportFromEPSG(4326)  # WGS84 EPSG code\n",
        "    options = gdal.WarpOptions(dstSRS=target_srs)\n",
        "    gdal.Warp(\"/vsimem/temp.tif\", dataset, options=options)\n",
        "\n",
        "    # Open the reprojected file\n",
        "    reprojected_dataset = gdal.Open(\"/vsimem/temp.tif\")\n",
        "\n",
        "    # Get geotransform information\n",
        "    geotransform = reprojected_dataset.GetGeoTransform()\n",
        "\n",
        "    # Get raster dimensions\n",
        "    width = reprojected_dataset.RasterXSize\n",
        "    height = reprojected_dataset.RasterYSize\n",
        "\n",
        "    # Calculate bounding box coordinates\n",
        "    min_lng = geotransform[0]\n",
        "    max_lng = geotransform[0] + width * geotransform[1] + height * geotransform[2]\n",
        "    max_lat = geotransform[3]\n",
        "    min_lat = geotransform[3] + width * geotransform[4] + height * geotransform[5]\n",
        "\n",
        "    # Close the reprojected dataset and delete the temporary file\n",
        "    reprojected_dataset = None\n",
        "    gdal.Unlink(\"/vsimem/temp.tif\")\n",
        "\n",
        "    return min_lng, min_lat, max_lng, max_lat\n"
      ],
      "metadata": {
        "id": "HiAD0tnNi6sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = merged_mask\n",
        "bounds = get_geotiff_bounds(file_path)\n",
        "print(\"Bounding box coordinates (min_lng(west), min_lat(south), max_lng(east), max_lat(north)):\", bounds)"
      ],
      "metadata": {
        "id": "uuqmzj-YjXEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raster to KLM"
      ],
      "metadata": {
        "id": "Kokr1mcjhsD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q simplekml\n",
        "!pip install -q rasterio"
      ],
      "metadata": {
        "id": "PScPoxbN-xbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "from shapely.geometry import shape, mapping\n",
        "import simplekml\n",
        "import pyproj\n",
        "\n",
        "def mask_to_kml(mask_path, kml_path, mask_value=1):\n",
        "    \"\"\"\n",
        "    Converts a GeoTIFF mask raster to a KML file, highlighting areas with a specific mask value\n",
        "    and including latitude and longitude information.\n",
        "\n",
        "    Args:\n",
        "        mask_path (str): Path to the GeoTIFF mask raster.\n",
        "        kml_path (str): Path to save the generated KML file.\n",
        "        mask_value (int, optional): Value in the mask raster representing the areas to highlight. Defaults to 1.\n",
        "    \"\"\"\n",
        "\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        image = src.read(1)  # Read the first band (assuming single-band mask)\n",
        "        transform = src.transform\n",
        "\n",
        "        # Get CRS and create transformer for lat/lon conversion\n",
        "        crs = src.crs\n",
        "        transformer = pyproj.Transformer.from_crs(crs, pyproj.CRS(\"EPSG:4326\"), always_xy=True)\n",
        "\n",
        "        # Extract shapes from mask\n",
        "        results = (\n",
        "            {'properties': {'raster_val': v}, 'geometry': s}\n",
        "            for i, (s, v) in enumerate(shapes(image, transform=transform))\n",
        "            if v == mask_value\n",
        "        )\n",
        "\n",
        "        # Create KML document\n",
        "        kml = simplekml.Kml()\n",
        "        fol = kml.newfolder(name=\"Mask Areas\")  # Create a folder to organize polygons\n",
        "\n",
        "        for result in results:\n",
        "            geom = shape(result['geometry'])\n",
        "\n",
        "            # Convert coordinates to lat/lon\n",
        "            lat_lon_coords = []\n",
        "            for x, y in geom.exterior.coords:\n",
        "                lon, lat = transformer.transform(x, y)\n",
        "                lat_lon_coords.append((lon, lat))\n",
        "\n",
        "            pol = fol.newpolygon(name=f\"Polygon {result['properties']['raster_val']}\")\n",
        "            pol.outerboundaryis = lat_lon_coords\n",
        "\n",
        "    kml.save(kml_path)"
      ],
      "metadata": {
        "id": "EoocfLgKh1aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_raster_path = merged_mask\n",
        "mask_kml_path = \"mask.kml\"\n",
        "mask_to_kml(mask_raster_path, mask_kml_path)  # Use default mask_value=1"
      ],
      "metadata": {
        "id": "O6oNvUZ4h3_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post proccesing and attribute extraction on KML"
      ],
      "metadata": {
        "id": "wGAdXEAgsbEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, Polygon\n",
        "import pandas as pd\n",
        "import fiona\n",
        "import simplekml\n",
        "\n",
        "def calculate_polygon_areas_and_export(kml_file, output_kml_file, tolerance=1, min_area=2.0):\n",
        "    # Read KML file\n",
        "    fiona.supported_drivers['KML'] = 'rw'\n",
        "    gdf = gpd.read_file(kml_file, driver='KML')\n",
        "\n",
        "    # Ensure it's a GeoDataFrame with polygons\n",
        "    if 'geometry' not in gdf.columns or gdf.geom_type[0] != 'Polygon':\n",
        "        raise ValueError(\"Input file does not contain polygon geometries.\")\n",
        "\n",
        "    # Simplify polygons using the Douglas-Peucker algorithm\n",
        "    gdf = gdf.to_crs(epsg=24047)\n",
        "    gdf['geometry'] = gdf['geometry'].simplify(tolerance, preserve_topology=True)\n",
        "\n",
        "    # Calculate areas\n",
        "    polygons = gdf[gdf.geometry.type == 'Polygon']\n",
        "\n",
        "    # Change name of polygons to their size (Google map displays the polygon names when clicked)\n",
        "    gdf['area'] = polygons.geometry.area\n",
        "    gdf['Name'] = gdf['area'].round(2)\n",
        "\n",
        "    gdf_min_area = gdf[gdf['area'] >= min_area]\n",
        "\n",
        "    total_area = gdf_min_area['Name'].sum().round(2)\n",
        "\n",
        "    gdf_min_area = gdf_min_area.to_crs(epsg=4326)\n",
        "\n",
        "    print(gdf_min_area)\n",
        "    print(total_area)\n",
        "\n",
        "    # Export to KML\n",
        "    kml = simplekml.Kml()\n",
        "    for index, row in gdf_min_area.iterrows():\n",
        "        poly = kml.newpolygon(name=str(row['Name'])+ \" m^2\", outerboundaryis=row['geometry'].exterior.coords[:])\n",
        "        poly.style.linestyle.color = simplekml.Color.rgb(0, 133, 0)\n",
        "        poly.style.linestyle.width = 2\n",
        "        poly.style.polystyle.fill = 1\n",
        "        poly.style.polystyle.color = simplekml.Color.changealphaint(200, simplekml.Color.rgb(0, 255, 0))\n",
        "\n",
        "    kml.save(output_kml_file)\n",
        "    print(\"KML file exported successfully.\")\n",
        "\n",
        "    return total_area"
      ],
      "metadata": {
        "id": "YJ18n2o0J4BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tolerance=1 # unit: meter\n",
        "min_area=2 # unit: meters squared\n",
        "input_kml_file = \"/content/mask.kml\"\n",
        "output_kml_file = \"/content/mask_simplified.kml\"\n",
        "\n",
        "try:\n",
        "  total_area = calculate_polygon_areas_and_export(input_kml_file, output_kml_file, tolerance, min_area)\n",
        "except Exception as e:\n",
        "  print('Polygons:', e) # no polygons\n"
      ],
      "metadata": {
        "id": "dxZzBwAtJwyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Power Generation formula"
      ],
      "metadata": {
        "id": "VidZK01I1kjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User inputs\n",
        "watt_per_m2 = 1000\n",
        "hours_per_day = 5\n",
        "effeciency = 0.15 # Average 15-20%\n",
        "\n",
        "# Daily Output (kWh) = Wattage (W) x Hours of Sunlight x Efficiency\n",
        "watt_hour = total_area * watt_per_m2\n",
        "daily_output = watt_hour/1000 * hours_per_day * effeciency\n",
        "print(\"Daily Output:\",np.round(daily_output,2), \"kWh\")"
      ],
      "metadata": {
        "id": "puTU18t-1DOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}