{"cells":[{"cell_type":"markdown","metadata":{},"source":["# I. Explore Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-31T11:26:59.403060Z","iopub.status.busy":"2024-05-31T11:26:59.402407Z","iopub.status.idle":"2024-05-31T11:27:07.556719Z","shell.execute_reply":"2024-05-31T11:27:07.555758Z","shell.execute_reply.started":"2024-05-31T11:26:59.403025Z"},"trusted":true},"outputs":[],"source":["%%capture\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:27:18.790085Z","iopub.status.busy":"2024-05-31T11:27:18.789396Z","iopub.status.idle":"2024-05-31T11:27:18.796887Z","shell.execute_reply":"2024-05-31T11:27:18.795898Z","shell.execute_reply.started":"2024-05-31T11:27:18.790044Z"},"trusted":true},"outputs":[],"source":["def show_images(images, titles=None):\n","    if not titles:\n","        titles = [img.shape for img in images]\n","    fig, axes = plt.subplots(nrows=1, ncols=len(images), figsize=(10, 30))\n","    for i, ax in enumerate(axes):\n","        ax.imshow(images[i], cmap=\"summer\")\n","        ax.set_title(titles[i])\n","        ax.axis(\"off\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:27:37.071389Z","iopub.status.busy":"2024-05-31T11:27:37.070871Z","iopub.status.idle":"2024-05-31T11:27:37.079581Z","shell.execute_reply":"2024-05-31T11:27:37.078679Z","shell.execute_reply.started":"2024-05-31T11:27:37.071337Z"},"trusted":true},"outputs":[],"source":["root_path = \"/kaggle/input/rooftop-solar-panel-thailand\" \n","categories_paths = os.listdir(root_path)\n","categories_paths = [os.path.join(root_path, cat_path) for cat_path in categories_paths]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:27:42.808288Z","iopub.status.busy":"2024-05-31T11:27:42.807594Z","iopub.status.idle":"2024-05-31T11:27:43.843118Z","shell.execute_reply":"2024-05-31T11:27:43.842161Z","shell.execute_reply.started":"2024-05-31T11:27:42.808248Z"},"trusted":true},"outputs":[],"source":["for cat_path in categories_paths:\n","    for _, _, files in os.walk(cat_path):\n","        print(\"{}: {}\".format(cat_path, len(files)))"]},{"cell_type":"markdown","metadata":{},"source":["Example of image and its mask."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-31T11:27:48.250506Z","iopub.status.busy":"2024-05-31T11:27:48.250105Z","iopub.status.idle":"2024-05-31T11:27:48.672302Z","shell.execute_reply":"2024-05-31T11:27:48.671310Z","shell.execute_reply.started":"2024-05-31T11:27:48.250476Z"},"trusted":true},"outputs":[],"source":["# Edit path to image and mask to see\n","image_path = '/kaggle/input/rooftop-solar-panel-thailand/rooftop_solar_panel_th/tile_0_0_png.rf.2b96fa13a01e34c1b9833be5b71770ea.jpg'\n","mask_path = '/kaggle/input/rooftop-solar-panel-thailand/rooftop_solar_panel_th/tile_0_0_png.rf.2b96fa13a01e34c1b9833be5b71770ea_mask.png'\n","image = plt.imread(image_path)\n","mask = np.expand_dims(plt.imread(mask_path), axis=(-1))\n","image_shape = image.shape\n","mask_shape = mask.shape\n","\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 20))\n","\n","axes[0].imshow(image)\n","axes[0].set_title('Shape: ' + str(image_shape))\n","\n","axes[1].imshow(mask, cmap=\"summer\")\n","axes[1].set_title('Shape: ' + str(mask_shape))\n","\n","[ax.axis(\"off\") for ax in axes]\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# II. Dataset Preparation"]},{"cell_type":"markdown","metadata":{},"source":["In this part, we should take care of several things:\n","* Creating a generator to read images from memory on the fly (during training).\n","* Spliting the dataset into train and test for further evaluation.\n","* Creating two datasets from the generators"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:28:51.021442Z","iopub.status.busy":"2024-05-31T11:28:51.020506Z","iopub.status.idle":"2024-05-31T11:28:51.219549Z","shell.execute_reply":"2024-05-31T11:28:51.218571Z","shell.execute_reply.started":"2024-05-31T11:28:51.021407Z"},"trusted":true},"outputs":[],"source":["images_paths = []\n","for cat_path in categories_paths:\n","    for root, _, files in os.walk(cat_path):\n","        cd_images = [os.path.join(root, file) for file in files]\n","        [images_paths.append(img) for img in cd_images]\n","images_paths = sorted(images_paths)\n","images_paths[:6]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:28:53.772320Z","iopub.status.busy":"2024-05-31T11:28:53.771694Z","iopub.status.idle":"2024-05-31T11:28:53.778411Z","shell.execute_reply":"2024-05-31T11:28:53.777470Z","shell.execute_reply.started":"2024-05-31T11:28:53.772282Z"},"trusted":true},"outputs":[],"source":["len(images_paths)"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the images are in the odd indices and their mask is in the next index, so knowing this structure, we will divide the indices to `train_idx` and `test_idx` and then create these generators:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:29:39.468949Z","iopub.status.busy":"2024-05-31T11:29:39.468298Z","iopub.status.idle":"2024-05-31T11:29:39.474341Z","shell.execute_reply":"2024-05-31T11:29:39.473264Z","shell.execute_reply.started":"2024-05-31T11:29:39.468920Z"},"trusted":true},"outputs":[],"source":["n_images = len(images_paths)\n","new_size = (512, 512)\n","images_idx = range(0, n_images, 2)\n","train_idx, test_idx = train_test_split(images_idx, test_size=0.15)"]},{"cell_type":"markdown","metadata":{},"source":["Create generator for train and test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:30:17.603281Z","iopub.status.busy":"2024-05-31T11:30:17.602602Z","iopub.status.idle":"2024-05-31T11:30:17.613585Z","shell.execute_reply":"2024-05-31T11:30:17.612414Z","shell.execute_reply.started":"2024-05-31T11:30:17.603248Z"},"trusted":true},"outputs":[],"source":["def train_dataset_generator():\n","    for i in train_idx:\n","        image = (\n","            tf.convert_to_tensor(plt.imread(images_paths[i]), dtype=tf.float32)\n","        )\n","        mask = (\n","            tf.convert_to_tensor(\n","                np.expand_dims(plt.imread(images_paths[i + 1])*255, axis=(-1)),\n","                dtype=tf.float32,\n","            )\n","            \n","        )\n","\n","        image = tf.image.resize(image, new_size)\n","        mask = tf.image.resize(mask, new_size)\n","\n","        yield image, mask\n","        \n","\n","def test_dataset_generator():\n","    for i in test_idx:\n","        image = (\n","            tf.convert_to_tensor(plt.imread(images_paths[i]), dtype=tf.float32)\n","        )\n","        mask = (\n","            tf.convert_to_tensor(\n","                np.expand_dims(plt.imread(images_paths[i + 1])*255, axis=(-1)),\n","                dtype=tf.float32,\n","            )\n","            \n","        )\n","\n","        image = tf.image.resize(image, new_size)\n","        mask = tf.image.resize(mask, new_size)\n","\n","        yield image, mask"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-05-19T11:52:07.572859Z","iopub.status.busy":"2023-05-19T11:52:07.57237Z","iopub.status.idle":"2023-05-19T11:52:07.606633Z","shell.execute_reply":"2023-05-19T11:52:07.604918Z","shell.execute_reply.started":"2023-05-19T11:52:07.572821Z"}},"source":["Create tensorflow datasets:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:31:12.509737Z","iopub.status.busy":"2024-05-31T11:31:12.508877Z","iopub.status.idle":"2024-05-31T11:31:14.785470Z","shell.execute_reply":"2024-05-31T11:31:14.784583Z","shell.execute_reply.started":"2024-05-31T11:31:12.509700Z"},"trusted":true},"outputs":[],"source":["train_dataset = tf.data.Dataset.from_generator(\n","    train_dataset_generator,\n","    output_signature=(\n","        tf.TensorSpec(shape=(*new_size, 3), dtype=tf.float32),\n","        tf.TensorSpec(shape=(*new_size, 1), dtype=tf.float32),\n","    ),\n",")\n","\n","test_dataset = tf.data.Dataset.from_generator(\n","    test_dataset_generator,\n","    output_signature=(\n","        tf.TensorSpec(shape=(*new_size, 3), dtype=tf.float32),\n","        tf.TensorSpec(shape=(*new_size, 1), dtype=tf.float32),\n","    ),\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["Next, we wil check if the dataset is working properly or not."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:31:16.055642Z","iopub.status.busy":"2024-05-31T11:31:16.055218Z","iopub.status.idle":"2024-05-31T11:31:17.032821Z","shell.execute_reply":"2024-05-31T11:31:17.031954Z","shell.execute_reply.started":"2024-05-31T11:31:16.055610Z"},"trusted":true},"outputs":[],"source":["for item in train_dataset.shuffle(20).take(1):\n","    show_images((item[0]/255,item[1]))"]},{"cell_type":"markdown","metadata":{},"source":["# III. UNet Model"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-05-19T12:10:59.652877Z","iopub.status.busy":"2023-05-19T12:10:59.652308Z","iopub.status.idle":"2023-05-19T12:10:59.663864Z","shell.execute_reply":"2023-05-19T12:10:59.661589Z","shell.execute_reply.started":"2023-05-19T12:10:59.652815Z"}},"source":["We will be utilizing the segmentation-models library to obtain a Unet model with a inceptionresnetv2 backbone. The Unet model is pretrained on the ImageNet dataset: https://www.image-net.org/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:31:54.554344Z","iopub.status.busy":"2024-05-31T11:31:54.553900Z","iopub.status.idle":"2024-05-31T11:32:08.833090Z","shell.execute_reply":"2024-05-31T11:32:08.831962Z","shell.execute_reply.started":"2024-05-31T11:31:54.554307Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install -U -q segmentation-models\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","\n","import segmentation_models as sm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:32:33.542669Z","iopub.status.busy":"2024-05-31T11:32:33.541714Z","iopub.status.idle":"2024-05-31T11:32:33.547838Z","shell.execute_reply":"2024-05-31T11:32:33.546578Z","shell.execute_reply.started":"2024-05-31T11:32:33.542625Z"},"trusted":true},"outputs":[],"source":["load_model = True\n","backbone = 'inceptionresnetv2'\n","batch_size = 16"]},{"cell_type":"markdown","metadata":{},"source":["Before going into training we need to make sure:\n","* The data is preprocessed regard to the backbone model.\n","* The dataset is splitted into train and validation dataset.\n","* The encoder part of the UNet is freezed so the model can be trained within a reasonable time frame."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:32:37.722489Z","iopub.status.busy":"2024-05-31T11:32:37.721710Z","iopub.status.idle":"2024-05-31T11:32:38.503985Z","shell.execute_reply":"2024-05-31T11:32:38.503052Z","shell.execute_reply.started":"2024-05-31T11:32:37.722454Z"},"trusted":true},"outputs":[],"source":["backbone_preprocess = sm.get_preprocessing(backbone)\n","preprocess_fn = lambda x, y: (backbone_preprocess(x), y)\n","\n","train_dataset = train_dataset.map(preprocess_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:32:40.070616Z","iopub.status.busy":"2024-05-31T11:32:40.070267Z","iopub.status.idle":"2024-05-31T11:32:40.212321Z","shell.execute_reply":"2024-05-31T11:32:40.211216Z","shell.execute_reply.started":"2024-05-31T11:32:40.070588Z"},"trusted":true},"outputs":[],"source":["def is_test(x, _):\n","    return x % 4 == 0\n","\n","def is_train(x, y):\n","    return not is_test(x, y)\n","\n","\n","recover = lambda x, y: y\n","\n","valid_dataset = train_dataset.enumerate().filter(is_test).map(recover).batch(batch_size)\n","\n","train_dataset = train_dataset.enumerate().filter(is_train).map(recover).batch(batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["Load pre-trained model from PV03 or create a new model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:34:26.785121Z","iopub.status.busy":"2024-05-31T11:34:26.784435Z","iopub.status.idle":"2024-05-31T11:34:39.473862Z","shell.execute_reply":"2024-05-31T11:34:39.473018Z","shell.execute_reply.started":"2024-05-31T11:34:26.785085Z"},"trusted":true},"outputs":[],"source":["if load_model:\n","    model_path = \"/kaggle/input/model_unet-inceptionresnetv2/tensorflow2/version1/3/model_unet-inceptionresnetv2_PV03.keras\"\n","    model = keras.models.load_model(\n","        model_path,\n","        custom_objects={\n","            \"dice_loss\": sm.losses.DiceLoss(),\n","            \"iou_score\": sm.metrics.IOUScore()\n","        },\n","    )\n","else:\n","    model = sm.Unet(\n","        backbone,\n","        classes=1,\n","        encoder_weights=\"imagenet\",\n","        encoder_freeze=True,\n","    )\n","    loss = sm.losses.DiceLoss()\n","    metrics = [sm.metrics.IOUScore(),'binary_accuracy',keras.metrics.Precision(),keras.metrics.Recall()]\n","    model.compile(\"Adam\", loss=loss, metrics=metrics)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T11:40:15.731067Z","iopub.status.busy":"2024-04-25T11:40:15.730734Z","iopub.status.idle":"2024-04-25T11:40:25.373360Z","shell.execute_reply":"2024-04-25T11:40:25.372625Z","shell.execute_reply.started":"2024-04-25T11:40:15.731040Z"},"trusted":true},"outputs":[],"source":["#keras.utils.plot_model(model, show_shapes=True) # Uncomment for seeing the model graph"]},{"cell_type":"markdown","metadata":{},"source":["# IV. Training Model"]},{"cell_type":"markdown","metadata":{},"source":["In this part we will train the model.\n","First we define a callback for visualize the learning process with one instance of the training dataset. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:36:25.076046Z","iopub.status.busy":"2024-05-31T11:36:25.075678Z","iopub.status.idle":"2024-05-31T11:36:25.084793Z","shell.execute_reply":"2024-05-31T11:36:25.083588Z","shell.execute_reply.started":"2024-05-31T11:36:25.076019Z"},"trusted":true},"outputs":[],"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_begin(self, epoch, logs=None):\n","        if (epoch + 1) % 5 == 0:\n","            for item in train_dataset.unbatch().shuffle(1).take(1):\n","                image = item[0]\n","                mask_4d = self.model.predict(np.expand_dims(image, axis=(0)))\n","                mask = np.squeeze(mask_4d, axis=0)\n","                image_converted = (image + 1) / 2\n","                show_images((image_converted, mask))\n","\n","display_cb = DisplayCallback()\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights='True')\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('model_unet-inceptionresnetv2_cp.keras', verbose=1, save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-31T11:36:32.040972Z","iopub.status.busy":"2024-05-31T11:36:32.039927Z","iopub.status.idle":"2024-05-31T11:36:33.143552Z","shell.execute_reply":"2024-05-31T11:36:33.142557Z","shell.execute_reply.started":"2024-05-31T11:36:32.040927Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["for item in train_dataset.unbatch().shuffle(10).take(2):\n","    image = item[0]\n","    mask = item[1]\n","    image_converted = (image + 1) / 2\n","    show_images((image_converted, mask))"]},{"cell_type":"markdown","metadata":{},"source":["The following code will train the model. In the case of training on the our dataset it will take around 20-30 minutes running on a P100 GPU with kaggle."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:42:13.185502Z","iopub.status.busy":"2024-05-31T11:42:13.184994Z","iopub.status.idle":"2024-05-31T11:52:34.439793Z","shell.execute_reply":"2024-05-31T11:52:34.438677Z","shell.execute_reply.started":"2024-05-31T11:42:13.185469Z"},"trusted":true},"outputs":[],"source":["with tf.device(\"/device:GPU:0\"):\n","    history = model.fit(\n","        train_dataset,\n","        batch_size=batch_size,\n","        epochs=100,\n","        validation_data=valid_dataset,\n","        callbacks=[display_cb, early_stopping_cb, checkpoint_cb],\n","    )\n","history = pd.DataFrame.from_dict(history.history)\n","\n","history.to_csv(\"history_unet-inceptionresnetv2.csv\", index=False)\n","model.save(\"model_unet-inceptionresnetv2.keras\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's take a look on train and validation loss and IoU score:"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-31T11:55:54.320374Z","iopub.status.busy":"2024-05-31T11:55:54.319365Z","iopub.status.idle":"2024-05-31T11:55:54.753251Z","shell.execute_reply":"2024-05-31T11:55:54.752303Z","shell.execute_reply.started":"2024-05-31T11:55:54.320338Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(15, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['loss'])\n","plt.plot(history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['iou_score'])\n","plt.plot(history['val_iou_score'])\n","plt.title('model IoU score')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# V. Evaluate Model"]},{"cell_type":"markdown","metadata":{},"source":["We will evaluate the model. Doing this, we will take 10 instances from test set and see the result, note that the model has never seen these images."]},{"cell_type":"markdown","metadata":{},"source":["Apply backbone preprocessing to test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:40:46.970429Z","iopub.status.busy":"2024-05-31T11:40:46.969410Z","iopub.status.idle":"2024-05-31T11:40:46.994144Z","shell.execute_reply":"2024-05-31T11:40:46.993291Z","shell.execute_reply.started":"2024-05-31T11:40:46.970391Z"},"trusted":true},"outputs":[],"source":["test_dataset = test_dataset.map(preprocess_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:56:00.441641Z","iopub.status.busy":"2024-05-31T11:56:00.440918Z","iopub.status.idle":"2024-05-31T11:56:06.957834Z","shell.execute_reply":"2024-05-31T11:56:06.956946Z","shell.execute_reply.started":"2024-05-31T11:56:00.441601Z"},"trusted":true},"outputs":[],"source":["threshold = 0.9\n","\n","for item in test_dataset.shuffle(100).take(10):\n","        image = item[0]     \n","        true_mask = item[1]\n","        mask_4d = model.predict(np.expand_dims(image, axis=(0)))\n","        pred_mask_proba = np.squeeze(mask_4d, axis=0)\n","        pred_mask = np.where(pred_mask_proba > threshold, 1, 0)\n","        \n","        image_converted = (image + 1) / 2\n","        \n","        show_images(\n","            (image_converted, true_mask, pred_mask_proba, pred_mask), \n","            [\"Image\", \"True Mask\", \"Model Probability\", \"Model Prediciton @\"+str(threshold)]\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T11:56:33.352535Z","iopub.status.busy":"2024-05-31T11:56:33.352090Z","iopub.status.idle":"2024-05-31T11:56:35.985982Z","shell.execute_reply":"2024-05-31T11:56:35.984925Z","shell.execute_reply.started":"2024-05-31T11:56:33.352503Z"},"trusted":true},"outputs":[],"source":["model.evaluate(test_dataset.batch(batch_size))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2735184,"sourceId":4778133,"sourceType":"datasetVersion"},{"datasetId":4878637,"sourceId":8227466,"sourceType":"datasetVersion"},{"modelInstanceId":32875,"sourceId":38960,"sourceType":"modelInstanceVersion"},{"modelInstanceId":32875,"sourceId":47621,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30476,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
